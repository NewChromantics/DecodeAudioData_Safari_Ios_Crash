<!DOCTYPE html>
<html>

<head>
<style>
body
{
	font-size:	30pt;
}
</style>
	<button onclick="Start()" style="width:200px;height:200px">Start test</button>
	<div id="SampleMeta">SampleMeta</div>
	<div id="DebugBox">Debug:</div>
	<script>
	let Pop = {};
	Pop.CreatePromise = function()
	{
		let Callbacks = {};
		let PromiseHandler = function(Resolve,Reject)
		{
			Callbacks.Resolve = Resolve;
			Callbacks.Reject = Reject;
		}
		let Prom = new Promise(PromiseHandler);
		Prom.Resolve = Callbacks.Resolve;
		Prom.Reject = Callbacks.Reject;
		return Prom;
	}
		
	Pop.Yield = function(Milliseconds)
	{
		const Promise = Pop.CreatePromise();
		setTimeout( Promise.Resolve, Milliseconds );
		return Promise;
	}
	
	let gAudioContext = null;
	const AudioContextPromise = Pop.CreatePromise();
	
	//	ffprobe silence
	//	 Duration: 00:00:00.85, start: 0.000000, bitrate: 346 kb/s
	//	Stream #0:0: Audio: mp3, 8000 Hz, mono, s16p, 8 kb/s
	//	Stream #0:1: Video: png, rgba(pc), 1080x1080 [SAR 2109:2109 DAR 1:1], 90k tbr, 90k tbn, 90k tbc
	//let SoundUrls = ['AudioAssets/Silence500.mp3'];
	
	//	ffprobe blue organ
	//	Duration: 00:01:14.06, start: 0.000000, bitrate: 160 kb/s
	//	Stream #0:0: Audio: mp3, 48000 Hz, stereo, s16p, 160 kb/s
	//let SoundUrls = ['AudioAssets/Blue/Cluster5_BluePlaneOrgan.mp3'];
	let SoundUrls = ['AudioAssets/Blue/Blue_30Secs.mp3'];
	const CropSoundSize = 1024*40;//null;

	//	if 	CreateSampleFromCode defined, the this is the params for createBuffer (channels, sampleframes, samplerate)
	//	44khz stereo
	//		10sec sample reaches 300
	//		60sec crashes around 50
	//	48khz (iphone 6s hardware smaple rate)
	//		30 sec stereo ~130
	//		30 sec mono ~250
	const SampleDurationSecs = 75;
	const CreateSampleFromCode = [2,SampleDurationSecs*48000,48000];
	//const CreateSampleFromCode = null;

	let SoundDatas = {};	//	[url]
	let Sounds = [];
	let SoundBuffers = [];
	
	
	
	//	fill a buffer with PCM
	function LoadAudioIntoBuffer(AudioBuffer,AudioData)
	{
		//	audiobuffer from audioCtx.createBuffer
		//	filll with noise
		for ( let c=0;	c<AudioBuffer.numberOfChannels;	c++)
		{
			const ChannelBuffer = AudioBuffer.getChannelData(c);
			for ( let s=0;	s<ChannelBuffer.length;	s++ )
			{
				ChannelBuffer[s] = AudioData[c][s];
			}
		}
	}
	
	function SetDivText(Name,Contents)
	{
		const DebugBox = document.querySelector(`#${Name}`);
		DebugBox.innerHTML = Contents;
	}
	
	function PushDebug()
	{
		const DebugBox = document.querySelector('#DebugBox');
		const DebugText = Array.from(arguments).join(', ');
		//	place new text at the top
		DebugBox.innerHTML = DebugText +'<br/>' + DebugBox.innerHTML;
	}
	function Debug()
	{
		console.log(...arguments);
		PushDebug(...arguments)
	}
	
	function CopyTypedArray(Data,SizeLimit)
	{
		SizeLimit = SizeLimit ? SizeLimit : Data.byteLength;
		SizeLimit = Math.min( SizeLimit, Data.byteLength );

		//	gr: no difference
		if ( false )
		{
			Debug(`Copying Typed Array...`);
			const OldArray = new Uint8Array(Data);
			const NewArray = new Uint8Array( SizeLimit );
			for ( let i=0;	i<Data.byteLength;	i++ )
				NewArray[i] = OldArray[i];
			return NewArray.buffer;
		}


		return Data.slice(0,SizeLimit);
	}
	
	async function DecodeAudioSample(AudioDataOrig)
	{
		const Context = await AudioContextPromise;
		const DecodePromise = Pop.CreatePromise();
		
		if ( CreateSampleFromCode )
		{
			const Buffer = Context.createBuffer( ...CreateSampleFromCode );
			DecodePromise.Resolve(Buffer);
			SetDivText('SampleMeta',`${CreateSampleFromCode}`);
		}
		else
		{
			const SliceSize = CropSoundSize ? CropSoundSize : AudioDataOrig.byteLength;
			//	decodeAudioData frees the underlying buffer to reduce memory usage,
			//	so we always need to slice/copy the buffer
			const AudioData = CopyTypedArray(AudioDataOrig,SliceSize);
			SetDivText('SampleMeta',`Compressed audio data x${AudioData.byteLength} bytes`);

			//	gr: "newer" api returns a promise, but safari ios errors with 1 arg, so is using old syntax
			//	https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/decodeAudioData
			Context.decodeAudioData(AudioData,DecodePromise.Resolve,DecodePromise.Reject);
		}
			
		const SoundBuffer = await DecodePromise;
		SoundBuffers.push(SoundBuffer);
		Debug(`Now have ${SoundBuffers.length} sound buffers`);
		return SoundBuffer;
	}

	function GetAudioContext()
	{
		if ( !gAudioContext )
		{
			const TAudioContext = window.AudioContext || window.webkitAudioContext;
			gAudioContext = new TAudioContext();
			AudioContextPromise.Resolve(gAudioContext);
		}
		return gAudioContext;
	}
	
	class Sound_t
	{
		constructor(AudioData)
		{
			this.AudioData = AudioData;
			this.Play().catch(Debug);
		}
		
		async Play()
		{
			const SampleBuffer = await DecodeAudioSample(this.AudioData);
			//	gr: test, dont store on self
			//	gr: if you dont store, crash ~80 (general oom?)
			this.SampleBuffer = SampleBuffer;
			
		}
	}
	
	async function LoadSoundDataNoise()
	{
		let Khz = NoisePcmKhz;
		let Secs = NoisePcmSecs;
		let Left = new Float32Array( Khz * Secs );
		let Right = new Float32Array( Khz * Secs );
		for ( let s=0;	s<Left.length;	s++ )
		{
			Left[s] = Math.random() * 2 - 1;	//	-1...1
			Right[s] = Math.random() * 2 - 1;	//	-1...1
		}
		return [Left,Right];
	}
	
	async function LoadSoundData(Url)
	{
		if ( !SoundDatas.hasOwnProperty(Url) )
		{
			const Response = await fetch(Url);
			const Contents = await Response.arrayBuffer();
			Debug(`Loaded ${Url} x${Contents.byteLength} bytes`);
			SoundDatas[Url] = Contents;
		}
		return SoundDatas[Url];
	}
	
	async function LoadSound(Url)
	{
		const Data = await LoadSoundData(Url);
		const Sound = new Sound_t(Data);
		Sounds.push(Sound);
	}
	
	function FreeSamples()
	{
		for ( let i=0;	i<SoundBuffers.length;	i++ )
		{
			if ( !SoundBuffers[i] )
				continue;
			Debug(`Free/nulling sample buffer ${i}`);
			SoundBuffers[i] = null;
		}
	}
	
	async function WaitForFrame()
	{
		const NewFramePromise = Pop.CreatePromise();
		function OnNewFrame()
		{
			NewFramePromise.Resolve();
		}
		requestAnimationFrame(OnNewFrame);
		return NewFramePromise;
	}
	
	const PooledItemChannels = 2;
	const PooledItemDurationSecs = 30;
	const PooledItemKhz = 48000;
	
	const NoisePcmKhz = PooledItemKhz;
	const NoisePcmSecs = 10;
	
	let PauseBetweenLoadingSound = 0;
	let NewSoundGroupDelay = 400;
	let Iterations = 900;
	let ConcurrentSounds = 10;
	const MaxPoolSize = ConcurrentSounds;
	let AudioBufferPool = null;
	let CreatedSoundNodes = 0;
	let FreedSoundNodes = 0;

	class Pool_t
	{
		constructor(Capacity=10,AllocNewPoolItemFunction=null)
		{
			this.UsedItems = [];
			this.FreeItems = [];
			
			this.Capacity = Capacity;
			this.AllocNewPoolItemFunction = AllocNewPoolItemFunction;
			
			//	promise queue
			this.OnFreeItemWaits = [];	//	array of promises waiting to be notified when an item becomes availible
		}
		
		async AllocNewPoolItem()
		{
			if ( this.AllocNewPoolItemFunction )
				return await this.AllocNewPoolItemFunction();
			throw `No AllocItemFunction specified, and AllocNewPoolItemFunction() not overloaded`;
		}
		
		GetPoolSize()
		{
			return this.UsedItems.length + this.FreeItems.length;
		}
		
		async WaitForFreeItem()
		{
			const Prom = Pop.CreatePromise();
			this.OnFreeItemWaits.push(Prom);
			//	flush immediately in case there are free items
			this.FlushFreeItemWaits();
			return Prom;
		}
		
		OnFreedItem()
		{
			this.FlushFreeItemWaits();
		}
		
		FlushFreeItemWaits()
		{
			if ( !this.FreeItems.length )
				return;
				
			//	wake up anything waiting
			//	gr: pop notifications from the array, don't while() otherwise
			//		we might get trapped in a loop (depending on JS engine and what the promise does)
			const Notifies = this.OnFreeItemWaits.splice(0,this.OnFreeItemWaits.length);
			Notifies.forEach( p => p.Resolve() );
		}
		
		async Alloc()
		{
			while(true)
			{
				//	take a free item
				if ( this.FreeItems.length )
				{
					const Item = this.FreeItems.shift();
					this.UsedItems.push(Item);
					return Item;
				}
				
				//	add more items to the  pool
				if ( this.GetPoolSize() < this.Capacity )
				{
					const NewItem = await this.AllocNewPoolItem();
					this.FreeItems.push(NewItem);
					this.OnFreedItem();
				}
				
				await this.WaitForFreeItem();
			}
		}
		
		Free(Item)
		{
			const UsedIndex = this.UsedItems.indexOf(Item);
			if ( UsedIndex < 0 )
				throw `Freeing item ${Item} that isn't in the used list`;
			this.UsedItems.splice(UsedIndex,1);
			this.FreeItems.push( Item);
			this.OnFreedItem();
		}
	}
	
	class AudioBufferPool_t extends Pool_t
	{
		constructor(AudioContext,Capacity=10)
		{
			super( Capacity );
			this.AudioContext = AudioContext;
		}
		
		async AllocNewPoolItem()
		{
			const Channels = PooledItemChannels;
			const SampleSecs = PooledItemDurationSecs;
			const Khz = PooledItemKhz;
			const Samples = SampleSecs * Khz;
			const Buffer = this.AudioContext.createBuffer( Channels, Samples, Khz );
			return Buffer;
		}	
	}
	

	async function AllocAudioBuffer(AudioContext)
	{
		if ( !AudioBufferPool )
			AudioBufferPool = new AudioBufferPool_t(AudioContext,MaxPoolSize);
		return await AudioBufferPool.Alloc();
	}
	
	function FreeAudioBuffer(AudioBuffer)
	{
		//	put back in pool
		AudioBufferPool.Free(AudioBuffer);
	}
	
	
	function CreateSoundNode(AudioContext,AudioBuffer)
	{
		const Source = AudioContext.createBufferSource();
		Source.buffer = AudioBuffer;
		Source.connect(AudioContext.destination);
		CreatedSoundNodes++;
		Debug(`CreatedSoundNodes=${CreatedSoundNodes}`);
		return Source;
	}
	
	function FreeSoundNode(SoundNode)
	{
		FreeAudioBuffer(SoundNode.buffer);
		SoundNode.stop();
		SoundNode.disconnect();
		SoundNode.buffer = null;
		FreedSoundNodes++;
		Debug(`FreedSoundNodes=${FreedSoundNodes}`);
	}
	
	async function TestRun()
	{
		Debug(`Waiting for audio context`);
		const AudioContext = await AudioContextPromise;
		Debug(`Got audio context`);

		for ( let i=0;	i<Iterations;	i++ )
		{
			let SoundNodes = [];
			
			function FreeSoundNodes()
			{
				for ( let sn=0;	sn<SoundNodes.length;	sn++ )
				{
					const SoundNode = SoundNodes[sn];
					FreeSoundNode(SoundNode);
					SoundNodes[sn] = null;
				}
			}
			
			for ( let s=0;	s<ConcurrentSounds;	s++ )
			{
				Debug(`Allocating ${s}/${ConcurrentSounds} in group ${i}`);
				const Pcm = await LoadSoundDataNoise();
				const AudioBuffer = await AllocAudioBuffer(AudioContext);
				LoadAudioIntoBuffer( AudioBuffer, Pcm );
				//await WaitForFrame();
				const SoundNode = CreateSoundNode(AudioContext,AudioBuffer);
				SoundNodes.push(SoundNode);
				SoundNode.start();
				await WaitForFrame();
				//await Pop.Yield(PauseBetweenLoadingSound);
			}
			//await LoadSound(SoundUrls[0]);
			//	gr: doesn't help, but force a wait for a render show debug appears
			await WaitForFrame();
			
			await Pop.Yield(NewSoundGroupDelay);
			FreeSoundNodes();
		}	
	}
	
	function Start()
	{
		TestRun().catch(Debug);
		GetAudioContext();
	}
	
	
	</script>
</body>

</html>
